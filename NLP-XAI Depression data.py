# -*- coding: utf-8 -*-
"""Copy of Untitled38.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h7H3ucPhIznTd_ES3K1DqjA7peTDiJ_f
"""

!pip install scikit-plot

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

import re
import string
from wordcloud import WordCloud
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

from nltk import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

data = pd.read_excel ("/content/dataset.xlsx")
data.head()

print(data.shape)

data=data.dropna(how='any')

data['label'].value_counts()

labels = [0,1]
sizes = [6240, 730]
custom_colours = ['#ff7675', '#74b9ff']

plt.figure(figsize=(20, 6), dpi=227)
plt.subplot(1, 2, 1)
plt.pie(sizes, labels = labels, textprops={'fontsize': 15}, startangle=140,
       autopct='%1.0f%%', colors=custom_colours, explode=[0, 0.05])

plt.subplot(1, 2, 2)
sns.barplot(x=labels,y = sizes, palette= 'viridis')

plt.show()

data['Total Words'] = data['text'].apply(lambda x: len(x.split()))

def count_total_words(text):
    char = 0
    for word in text.split():
        char += len(word)
    return char

data['Total Chars'] = data["text"].apply(count_total_words)

data.head()

plt.figure(figsize = (10, 6))
sns.kdeplot(x = data['Total Words'], hue= data['label'], palette= 'winter', shade = True)
plt.show()

plt.figure(figsize = (10, 6))
sns.kdeplot(x = data['Total Chars'], hue= data['label'], palette= 'winter', shade = True)
plt.show()

data.head()

def convert_lowercase(text):
    text = text.lower()
    return text

data['text'] = data['text'].apply(convert_lowercase)

def remove_url(text):
    re_url = re.compile('https?://\S+|www\.\S+')
    return re_url.sub('', text)

data['text'] = data['text'].apply(remove_url)

exclude = string.punctuation

def remove_punc(text):
    return text.translate(str.maketrans('', '', exclude))

data['text'] = data['text'].apply(remove_punc)

import nltk
nltk.download('punkt')
def remove_stopwords(text):
    new_list = []
    words = word_tokenize(text)
    stopwrds = stopwords.words('english')
    for word in words:
        if word not in stopwrds:
            new_list.append(word)
    return ' '.join(new_list)

data['text'] = data['text'].apply(remove_stopwords)

def perform_stemming(text):
    stemmer = PorterStemmer()
    new_list = []
    words = word_tokenize(text)
    for word in words:
        new_list.append(stemmer.stem(word))

    return " ".join(new_list)

data['text'] = data['text'].apply(perform_stemming)

data['Total Words After Transformation'] = data['text'].apply(lambda x: np.log(len(x.split())))

data.head()

text = " ".join(data[data['label'] == 0]['text'])
plt.figure(figsize = (15, 10))
wordcloud = WordCloud(max_words=500, height= 800, width = 1500,  background_color="black", colormap= 'viridis').generate(text)
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

text = " ".join(data[data['label'] == 1]['text'])
plt.figure(figsize = (15, 10))
wordcloud = WordCloud(max_words=500, height= 800, width = 1500,  background_color="black", colormap= 'viridis').generate(text)
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

all_nodep_words = []
for sentence in data[data['label'] == 0]['text'].to_list():
    for word in sentence.split():
        all_nodep_words.append(word)

df = pd.DataFrame(Counter(all_nodep_words).most_common(25), columns= ['Word', 'Frequency'])

sns.set_context('notebook', font_scale= 1.3)
plt.figure(figsize=(18,8))
sns.barplot(y = df['Word'], x= df['Frequency'], palette= 'summer')
plt.title("Most Commonly Used Words When Not Depressed")
plt.xlabel("Frequnecy")
plt.ylabel("Words")
plt.show()

all_dep_words = []
for sentence in data[data['label'] == 1]['text'].to_list():
    for word in sentence.split():
        all_dep_words.append(word)

df = pd.DataFrame(Counter(all_dep_words).most_common(25), columns= ['Word', 'Frequency'])

sns.set_context('notebook', font_scale= 1.3)
plt.figure(figsize=(18,8))
sns.barplot(y = df['Word'], x= df['Frequency'], palette= 'summer')
plt.title("Most Commonly Used Words When Depressed")
plt.xlabel("Frequnecy")
plt.ylabel("Words")
plt.show()

X = data["text"]
y = data['label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42, stratify = y)

tfidf = TfidfVectorizer(max_features= 2500, min_df= 2)
X_train = tfidf.fit_transform(X_train).toarray()
X_test = tfidf.transform(X_test).toarray()

def train_model(model):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)
    accuracy = round(accuracy_score(y_test, y_pred), 3)
    precision = round(precision_score(y_test, y_pred), 3)
    recall = round(recall_score(y_test, y_pred), 3)

    print(f'Accuracy of the model: {accuracy}')
    print(f'Precision Score of the model: {precision}')
    print(f'Recall Score of the model: {recall}')

    sns.set_context('notebook', font_scale= 1.3)
    fig, ax = plt.subplots(1, 2, figsize = (25,  8))

    # Import necessary function for confusion matrix plotting
    from sklearn.metrics import ConfusionMatrixDisplay

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap=plt.cm.Blues, ax=ax[0])  # Plot on the first subplot

    from sklearn.metrics import roc_curve, roc_auc_score

    # Assuming you have y_true (true labels) and y_score (predicted probabilities)
    fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1]) # Use y_prob for class 1
    roc_auc = roc_auc_score(y_test, y_prob[:, 1])

    # Plot ROC on the second subplot
    ax[1].plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    ax[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    ax[1].set_xlim([0.0, 1.0])
    ax[1].set_ylim([0.0, 1.05])
    ax[1].set_xlabel('False Positive Rate')
    ax[1].set_ylabel('True Positive Rate')
    ax[1].set_title('Receiver Operating Characteristic')
    ax[1].legend(loc="lower right")

    plt.show() # Dedent plt.show() to be outside the function

nb = MultinomialNB()
train_model(nb)

rf = RandomForestClassifier(n_estimators= 300)
train_model(rf)

!pip install lime
# Import the LimeTabularExplainer module
from lime.lime_tabular import LimeTabularExplainer

# Get the class names
class_names = ['depressed', 'Not depressed']

# Get the feature names
feature_names = tfidf.get_feature_names_out()

# X_train is already a dense array, no need to call toarray()
X_train_dense = X_train

# Fit the Explainer on the training data set using the LimeTabularExplainer
explainer = LimeTabularExplainer(X_train_dense,
                                 feature_names=feature_names,
                                 class_names=class_names,
                                 mode='classification')

idx = 0  # For example, the first instance in your test set
instance = X_test[idx]

# Generate an explanation
explanation = explainer.explain_instance(instance, rf.predict_proba, num_features=10)

# Now you can plot the explanation
fig = explanation.as_pyplot_figure()
plt.show()

idx = 0  # For example, the first instance in your test set
instance = X_test[idx]

# Generate an explanation
explanation = explainer.explain_instance(instance, rf.predict_proba, num_features=20)

# Now you can plot the explanation
fig = explanation.as_pyplot_figure()
plt.show()



idx = 0  # For example, the first instance in your test set
instance = X_test[idx]

# Generate an explanation
explanation = explainer.explain_instance(instance, rf.predict_proba, num_features=20)

# Now you can plot the explanation
fig = explanation.as_pyplot_figure()
plt.show()



!pip install lime
import lime.lime_text  # Import the correct module for text data
import numpy as np

# Assuming 'clf' is your trained text classifier (e.g., text_clf from previous examples)
explainer = lime.lime_text.LimeTextExplainer(
    class_names=['not depressed', 'depressed']  # Replace with your actual class names
)
idx = 2  # Index of the instance to explain

# **Make sure 'vectorizer' is defined here,
# it should be the same one used during training**
vectorizer = tfidf

exp = explainer.explain_instance(X.iloc[idx],
                                 lambda texts: rf.predict_proba(vectorizer.transform(texts)), # Vectorize the text before prediction
                                 num_features=5)

# Visualize the explanation
exp.as_pyplot_figure()



!pip install lime
import lime.lime_text  # Import the correct module for text data
import numpy as np
explainer = lime.lime_text.LimeTextExplainer(
class_names=['not depressed', 'depressed'])  # Replace with your actual class names
idx >=100 # Index of the instance to explain
predict_fn = lambda texts: rf.predict_proba(vectorizer.transform(texts))

exp = explainer.explain_instance(X.iloc[idx],
                                  predict_fn,
                                  num_features=10)


# Visualize the explanation
exp.as_pyplot_figure()